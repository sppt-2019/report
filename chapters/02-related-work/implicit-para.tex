\section{Implicit Parallelisation}
Functional programming has long claimed to be inherently parallelisable\cite{hudak1986functional, loidl1998granularity}. The claimed advantage of functional programs is the high degree of modularity, which simplifies the parallelisation process. A number of languages have attempted to implement programming systems the utilise this advantage, however few have reached mainstream use. In this section we will explores the theoretical background for a implementing a implicitly parallelisable system in \fs.

First different evaluation strategies are explored, since \fs supports both strict and non-strict evaluation. In addition to these to dominant evaluation strategies, another promising strategy, called lenient evaluation, is examined. Once the strategies are outlined, the question of when to parallelise is addressed with the work/span methodology.

\input{chapters/02-related-work/evaluation-strat.tex}
\input{chapters/02-related-work/workspan.tex}

\subsection{Lenient Parallelisation}
Using a highly granular parallelisation system such as \m{.NET} \m{Tasks}. Function arguments would be evaluated as a task each, unless the expression is too small. Determining the computational cost of an argument is calculated by estimating the work of the expression. This information along with the span of the program should provide enough information to the system to effectively parallelise a \fs program.
