\subsection{Unity Garbage Collection}
In this section we first examine best pratices for developing applications in Unity with a particular focus on garbage. We then list different \gls{GC} algorithms, briefly characterise them and investigate which algorithms are used in Mono, dotnet and Unity. Finally we measure the running times of F\# against C\# in Unity and a functional map-based approach against an imperative one.

\subsubsection{Best Practices}
Unity recommends careful memory management when writing in C\# and avoiding unnecessary heap allocations\cite{unity:optimisation}. The performance optimisation guideline in \cite{unity:optimisation} lists many common performance bottlenecks for Unity developers. The most notable of those are lack of caching and extensive use of boxing. Unity provides many methods and properties that allow developers to access collections of components, such as the \ttt{GameObject.FindObjectsWithTag} method and \ttt{Mesh.vertices} property\cite{unity:optimisation, unity:heap}. The implementation of those methods will allocate a new array for the objects behind the scenes every time they're invocated. We list an example of this from \cite{unity:heap} as \ttt{Wrong} in \lstref{unity:array:prop}. In the example \ttt{mesh.veritices} might seem like an innocent property access, but each time the property is accessed, a new array is allocated. This means that the code allocates four new arrays in every iteration of the loop. This puts a huge burden on the \gls{GC} and will, according to \cite{unity:heap}, result in notisable performance degredation. Instead, developers should use the code listed as \ttt{Correct} in \lstref{unity:array:prop}, which does the exact same, but only allocates one array for all iterations, due to better use of caching.

The problems highlighted in \lstref{unity:array:prop} are an instance of common subexpression elimination, and one could speculate whether or not Unity's C\# compiler should be capable of performing such optimisations. Nevertheless, Unity's best practise guidelines list them as an example and explain how developers should transform their code manually\cite{unity:heap}.

\begin{listing}
\begin{minted}{csharp}
//sample implementation of mesh.vertices
class Mesh {
    public Vector3[] vertices {
        get {
            var verts = new Vector3[/*number of vertices*/]
            //find the vertices and put them into verts
            return verts;
        }
    }
}

//Wrong
for(int i = 0; i < mesh.vertices.Length; i++)
{
    float x, y, z;

    x = mesh.vertices[i].x;
    y = mesh.vertices[i].y;
    z = mesh.vertices[i].z;

    DoSomething(x, y, z);
}

//Correct
var verts = mesh.vertices;
for (var i = 0; i < verts.Length; i++) {
    DoSomething(verts[i].x, verts[i].y, verts[i].z);
}
\end{minted}
\caption{Common performance bottleneck in Unity \cite{unity:heap}. \ttt{mesh.vertices} should be cached.} \label{lst:unity:array:prop}
\end{listing}

The problem of boxing occurs when a value-type should be used by refrence, for instance when constructing a list of integers or appending a float to a string. This generates a small ammount of garbage, which can quickly accumulate, e.g. during list iterations. Furthermore, \cite{unity:optimisation} underlines the importance of avoiding \gls{LINQ}-statements all together, due to the garbage generated under the hood. \cite{unity:heap} recommends avoiding coding styles that requires passing functions as arguments and to completely avoid closures, due to the ammount of garbage generated by said language constructs.

\subsubsection{Garbage Collection Algorithm}
Unity uses the Boehm–Demers–Weiser \gls{GC}, which is a conservative mark-sweep \gls{GC}\cite{unity:heap}, originally created for automatic memory management in C and C++\cite{boehm2007transparent}. Mark-sweep algorithms are the simplest type of \glspl{GC} and has the primary disadvantages that they halt computation while running, increase in execution time as more objects are allocated and may fragment memory\cite{sestoft2017programming}.

The dotnet runtime uses a generational \gls{GC} with three generations for smaller objects and a single generation for large objects\cite{dotnet:gc}. The younger generations are collected more often than the higher and all surviving objects are moved to the older generations. Each time an older generation is collected, all younger generations are also collected. Generational \glspl{GC} have the advantage that short-lived object allocations have a smaller performance penalty, but the disadvantage that they introduce additional overhead if old objects contain references to young objects\cite{sestoft2017programming}. Depending on the system the dotnet runtime may use different \gls{GC} strategies, including concurrent versions\cite{dotnet:gc}. Concurrent \glspl{GC} can collect garbage concurenly with the computation, meaning that \gls{GC} pauses are minimised or entirely removed\cite{dotnet:gc}.

Mono has previously used the Boehm–Demers–Weiser \gls{GC}, but has since moved to a concurrent, generational \gls{GC} called sgen\cite{mono:gc}. We have previously mentioned that Unity uses the Mono runtime, which may cause some confusion, so a clarification is due. Unity supports two different runtimes: Mono and IL2CPP. Unity's Mono runtime is a fork of the official Mono runtime\cite{unity:mono:github}, meaning that updates to the official Mono is not necessarily applied to the Unity's Mono runtime. The IL2CPP runtime \gls{AoT} compiles code in \gls{IL} to C++, which also uses the Boehm–Demers–Weiser \gls{GC}\cite{il2cpp:gc}. However, as part of Unity's 2019.1.0 release an experimental \textit{\dquote{incremental garbage collector, which should reduce stutters and time spikes}} was added\cite{unity:roadmap}.

\subsubsection{Functional Programming and Garbage Collection}
All these recommendations stand in direct contrast to the common practices employed in the pure functional programming paradigm. In functional programming it's typical to map over collections, which has two problems compared to this Unity performance guideline:
\begin{enumerate}
    \item map allocates a new collection instead of mutating the existing collection.
    \item map requires a function as one of the arguments, which defines what should happen to each of the elements in the collection.
\end{enumerate}
This practise also extends to other generalised constructs, such as the tree-walker\needcite. These guidelines explain why Unity Technologies does not want to add F\# support, despite over 3500 votes on their feedback forums in April 2018\cite{unity:fsharp}. The vote was later closed by Unity, without any explanation\footnote{In previous work we have cited the Unity forums to support this claim\cite{p92018gameplay}, but as of Feburary 2019 Unity has closed their feedback forums, meaning that this citation is no longer valid.}.

\subsubsection{Investigating Performance}
%Unity's performance guidelines regarding \gls{GC} seems to convey the message that functional-style programming should be avoided in Unity. However,
\gls{GC} is not the only thing that may affect performance in a managed language. There is also the problem of calling from the native (or unmanaged) code to the managed code. An investigation of Unity's integration with the managed runtime shows that a there is a considerable overhead in calling the pre-defined \ttt{MonoBehaviour}-methods (such as \ttt{Update}) in Unity 5.2.2\cite{unity:runtime:calls}. In \cite{unity:runtime:calls} the author sets up two different scenes:
\begin{enumerate}
    \item A scene containing 10,000 separate \ttt{MonoBehaviour}s with an \ttt{Update}-method that increments a variable.
    \item A scene containing one \ttt{MonoBehaviour}, which contains an array of 10,000 objects. Each time the \ttt{Update}-method is called, the \ttt{MonoBehaviour} iterates through the 10,000 objects and calls a custom \ttt{MyUpdate}-method.
\end{enumerate}
On an iPhone 6 the first approach took an average of 5.4ms to update the 10,000 objects, whereas the second took 0.22ms\cite{unity:runtime:calls}. In the first approach only 0.4\% of the time is spent actually executing the \ttt{Update}-code, the remaining 99.6\% is spent doing sanity checks, iterating \ttt{MonoBehaviours} and instrumenting calls from the native code into the runtime\cite{unity:runtime:calls}.

\subsubsection{Test Setup}
The question then arises if the (potentially) increased overhead from \gls{GC} can be outweighed by having a single \ttt{MonoBehaviour} manage several other behaviours in the same scene. In order to investigate, we reused the implementation of the Unit Management test case from the usability test (see \secref{usability:test:cases}). This solution is listed in \lstref{test:case:ai}. This test case may be solved by creating a collection of tuples: \ttt{(Unit, State)}. The state machine contains a series of unit management methods; one for each state. These methods take a unit as argument and returns a state. At each iteration the corresponding state's methods are mapped over the collection to create a new collection of game objects and their updated state, which is stored for the subsequent update. This approach avoids dealing with the problems of updating the list while iterating and potentially applying two updates to one \ttt{GameObject}. The advantage is that a single \ttt{MonoBehaviour} is in charge of updating all units in the \dquote{Realtime Strategy Game} and the disadvantage is that it generates substantially more garbage, as a new collection is allocated at each \ttt{Update}. We refer to this method as \dquote{Inverse} in the remainder of this section.

The other approach, here referred to as \dquote{Normal}, creates a \ttt{MonoBehaviour} for each unit, which contains it's own state machine. This has the advantage that we can exploit caching and generate less garbage, as suggested by Unity Technologies\cite{unity:optimisation}. It comes at the disadvantage that each unit must have its own \ttt{Update}-method, potentially introducing a large overhead\cite{unity:runtime:calls}.

\begin{listing}
\begin{minted}{csharp}
public void Update()
{
    //Apply updates and store the updated states in a list
    var newStates = _stateList.Select(s =>
    {
        switch (s.state)
        {
            case State.Fleeing:
                return Flee(s.entity);
            case State.Moving:
                return Move(s.entity);
            case State.Attacking:
                return Attack(s.entity);
            default: return (State.Moving, s.entity);
        }
    }).ToList();

    //zip the list with the old states to create tuples: (new state, old state)
    foreach (var statePair in newStates.Zip(_stateList, (sNew, sOld) => (sNew,sOld)))
    {
        //Compare old state and new state, initialise the unit for the new state if changed
        if (statePair.sNew.Item1 != statePair.sOld.state)
        {
            _initialiseState(statePair.sNew.Item1, statePair.sNew.entity);
            //Create a new list containing the updated unit
            // _stateLise = _stateList.Select(s => s.entity == shooter ? (state, shooter) ? s);
        }
    }
}
\end{minted}
\caption{Possible solution for the Unit Management test cases.}
\label{lst:test:case:ai}
\end{listing}

\subsubsection{Methodology}
We decided to implement the two approaches in both C\# and F\#. We run the test using the il2cpp runtime under Unity 2019.1.0f2. In all test cases we used a \ttt{MonoBehaviour} written in C\# to measure the time between each \ttt{Update}-call, i.e. the time it takes to generate a frame. We decided to run the test in five setups with 500, 1000, 1500, 2000 and 2500 units. For each setup we generated 900 frames, as that corresponds to 15 seconds of gameplay at 60 \glspl{FPS}. Each measurement was added to a \ttt{HashSet}, which was written to a CSV file after the test. This means that the measurements include all game-related code, both including rendering, physics and so alike. However, as this system is ultimately going to be used to develop games, we conclude that delta time (or equivalently \gls{FPS}) is a good metric, as that is of utmost importance to the player.

The following research questions outlines the intend of the experiment:
\begin{itemize}
    \item How does the performance penalty from extensive garbage generation compare to the performance penalty from an increased number of calls between unmanaged and managed runtimes?
    \item Does \gls{AoT}-compilation in the il2cpp runtime actually provide a speed up?
    \item Does the use of F\# (and \gls{FRP}) introduce an additional overhead?
    \item Unity introduced a new incremental \gls{GC} in Unity 2019.1. Does this new \gls{GC} provide a speed-up when using either C\# or \gls{FRP}?
\end{itemize}

\subsection{Results}
In this section we discuss the results from the benchmarks. We use the questions presented in the previous section as baseline for the discussion.

\subsubsection{Performance Penalty from Extensive Garbage Generation}
The results are listed in \tableref{unity:ai} and plotted in \figref{ai:benchmark}. The results indicate that F\# adds a small overhead, which increases as the number of units grow. This can be seen by comparing C\# Normal and F\# Normal. Furthermore, the C\# Inverse also adds a small overhead compared to C\# Normal. This could indicate that Unity has optimised the calls between native and managed code since v5.2.2. We also observe that the inverse FRP state machine performs notably worse than the other approaches as the number of units grow. We will go into greater depth as to why in the following section.

\begin{table}[H]
    \sisetup{round-mode=places}
    \rowcolors{1}{}{lightgray}
    \makebox[\textwidth][c]{
    \begin{tabular}{P{4cm} | S[round-precision=2] | S[round-precision=2] | S[round-precision=2] | S[round-precision=2]}
        \textbf{Number of Units} & \textbf{C\#} & \textbf{C\# Inverse} & \textbf{F\#} & \textbf{FRP Inverse}
        \csvreader[head to column names]{00-data/ai-benchmark.csv}
        {1=\strategy, 2=\csharp, 3=\cinverse, 4=\fsharp, 5=\frp} % <Column number>=<Macro>
        {\\\hline \strategy & \csharp & \cinverse & \fsharp & \frp}
    \end{tabular}}
    \caption{Average framerate when simulating the given number of units in Unity's Mono runtime.}
    \label{tab:unity:ai}
\end{table}

\barChart*[12][\symbolic{Strategy,500,1000,1500,2000,2500}][Average FPS][Number of Units]{Average FPS in Unit Management benchmark}{ai:benchmark}{
    \plotData{Csharp Normal}{\aiBenchmarkData}
    \plotData{Csharp Inverse}{\aiBenchmarkData}
    \plotData{Fsharp Normal}{\aiBenchmarkData}
    \plotData{FRP Inverse}{\aiBenchmarkData}
}

\subsubsection{Performance of Runtimes}
The results, listed in \tableref{unity:ai:runtime} and plotted in \figref{ai:benchmark:runtime}, show that il2cpp does not necessarily provide a speed up. We deem this as C\# Normal is faster in Mono, whereas il2cpp provides roughly 2 more \gls{FPS} in C\# Inverse and F\# Normal.

Another interesting observation we made during the test is that there is a very large spike in the time it takes to generate the third frame. This spike is around 20 times the time it takes to generate the other frames. One could explain this spike in Mono as runtime-optimisation, but as it is also present in il2cpp, which is \gls{AoT}, that cannot be the case. We do therefore not know what causes the spike.

\begin{table}[H]
    \sisetup{round-mode=places}
    \rowcolors{1}{}{lightgray}
    \makebox[\textwidth][c]{
    \begin{tabular}{P{4cm} | S[round-precision=2] | S[round-precision=2]}
        \textbf{Runtime} & \textbf{il2cpp} & \textbf{Mono}
        \csvreader[head to column names]{00-data/ai-benchmark-runtimes.csv}
        {1=\strategy, 2=\iltocpp, 3=\mono} % <Column number>=<Macro>
        {\\\hline \strategy & \iltocpp & \mono}
    \end{tabular}}
    \caption{Average framerate in Unity's two runtimes measured with 250 unites in the scene.}
    \label{tab:unity:ai:runtime}
\end{table}

\barChart[12][\symbolic{Strategy,Csharp Normal,Csharp Inverse,Fsharp Normal,FRP Inverse}][Average FPS][Strategy]{Average FPS in Unit Management benchmark}{ai:benchmark:runtime}{
    \plotData{Mono}{\aiBenchmarkRuntimesData}
    \plotData{il2cpp}{\aiBenchmarkRuntimesData}
}

\subsubsection{Performance of the FRP-system}
The results are plotted in \figref{ai:benchmark:overhead}. The results show that \gls{FRP} introduces additional overhead. This overhead results in a decrease of ten \gls{FPS} on average over the 900 frames. On the other hand, the \gls{FRP}-system yields a smoother curve, which means that the game will be subject to less stuttering and fewer lag spikes.

\lineChart[enlarge x limits=false,xtick={0,100, 200, 300, 400, 500, 600, 700, 800, 900}][FPS][Frame No.]{FPS for each frame in FRP and C\# Inverse}{ai:benchmark:overhead}{
    \plotUnmarkedData{Csharp}{\aiBenchmarkOverheadData}
    \plotUnmarkedData{FRP}{\aiBenchmarkOverheadData}
}

The problems with the \gls{FRP}-system is that each \ttt{FRPBehaviour} is actually a full-blown \gls{FRP}-system, which could very well be refactored into a singleton.

Solving this problem would require a larger refactoring, as this relates to the Unity lifecycle of \ttt{GameObject}s. First and foremost some Unity methods are required to be tied to the \ttt{GameObject} they belong to. Examples of such methods are \ttt{OnCollisionEnter} and \ttt{OnTriggerExit}. Other methods, such as \ttt{Update} and reacting to keyboard strokes could, on the other hand, be tied to a \ttt{FRPEngine}. The problem here arises when \ttt{GameObject}s are destroyed. We have not added support to remove \ttt{FRPBehaviour}s from the \gls{FRP}-system, as the current version \dquote{cleans} up after itself when \ttt{GameObject}s are destroyed. This is to be understood in the sense that the whole system is deallocated and thus never risks invoking event handlers on objects that have been destroyed.

In order to truely determine whether or not \gls{FRP} comes with a performance penalty, these changes would have to be incorporated.

\subsection{Unity's Incremental Garbage Collector}
The results from running the C\# Normal implementation with the two different runtimes and \glspl{GC} are plotted in \figureref{ai:benchmark:csharp:gc:bar}. These results show that the two \glspl{GC} perform more or less equivalently. It might even seem that the incremental \gls{GC} performs worse than the original after the curve stabilises after the 350th frame.

In general, the incremental \gls{GC} has lower variation, except from Mono after frame 650 where the \gls{FPS} varies wildly.

\barChart[5][enlarge x limits={value=0.035,auto},width=1.3\textwidth,xtick=data,\symbolic{0-49,50-99,100-149,150-199,200-249,250-299,300-349,350-399,400-449,450-499,500-549,550-599,600-649,650-699,700-749,750-799,800-849,850-899}][FPS][Frame No.]{FPS for each frame in C\# using the two different Unity GC}{ai:benchmark:csharp:gc:bar}{
  \plotDataWithError{il2cpp}{\aiCsharpGCDataCol}
  \plotDataWithError{Mono}{\aiCsharpGCDataCol}
  \plotDataWithError{Incremental il2cpp}{\aiCsharpGCDataCol}
  \plotDataWithError{Incremental Mono}{\aiCsharpGCDataCol}
}

We also tested the two \glspl{GC} with the \gls{FRP}-system we developed in F\#. The results are plotted in \figref{ai:benchmark:fsharp:gc:bar}. These results show that the incremental \gls{GC} performs slightly better than the original one. However, it comes at the cost of much higher variation in the framerate, especially in the Mono runtime. The il2cpp incremental curve has large spikes up until around the 200th frame, after which point it stabilises within 5-8 \gls{FPS} variation. The Mono curve continues to variate with nearly 30 \gls{FPS}.

\barChart[5][enlarge x limits={value=0.035,auto},width=1.3\textwidth,xtick=data,\symbolic{0-49,50-99,100-149,150-199,200-249,250-299,300-349,350-399,400-449,450-499,500-549,550-599,600-649,650-699,700-749,750-799,800-849,850-899}][FPS][Frame No.]{FPS for each frame in F\# using the two different Unity GC}{ai:benchmark:fsharp:gc:bar}{
  \plotDataWithError{il2cpp}{\aiFsharpGCDataCol}
  \plotDataWithError{Mono}{\aiFsharpGCDataCol}
  \plotDataWithError{Incremental il2cpp}{\aiFsharpGCDataCol}
  \plotDataWithError{Incremental Mono}{\aiFsharpGCDataCol}
}
