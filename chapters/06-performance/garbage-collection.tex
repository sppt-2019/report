\section{Unity Garbage Collection}
In this section we first examine best pratices for developing applications in Unity with a particular focus on garbage. We then list different \gls{GC} algorithms, briefly characterise them and investigate which algorithms are used in Mono, dotnet and Unity. Finally we measure the running times of F\# against C\# in Unity and a functional map-based approach against an imperative one.

\subsection{Best Practices}
Unity recommends careful memory management when writing in C\# and avoiding unnecessary heap allocations\cite{unity:optimisation}. The performance optimisation guideline in \cite{unity:optimisation} lists many common performance bottlenecks for Unity developers. The most notable of those are lack of caching and extensive use of boxing. Unity provides many methods and properties that allow developers to access collections of components, such as the \ttt{GameObject.FindObjectsWithTag} method and \ttt{Mesh.vertices} property\cite{unity:optimisation, unity:heap}. Each of those methods and properties allocate a new array for the objects at every invocation, meaning that the code listed as \ttt{Wrong} in \lstref{unity:array:prop} allocates four arrays in every iteration of the loop. This puts a huge burden on the \gls{GC} and will, according to \cite{unity:heap}, result in notisable performance degredation. Instead, developers should use the code listed as \ttt{Correct} in \lstref{unity:array:prop}, which does the exact same, but with better use of caching.

\begin{listing}
    \begin{minted}{csharp}
        //Wrong
        for(int i = 0; i < mesh.vertices.Length; i++)
        {
            float x, y, z;

            x = mesh.vertices[i].x;
            y = mesh.vertices[i].y;
            z = mesh.vertices[i].z;

            DoSomething(x, y, z);
        }

        //Correct
        var verts = mesh.vertices;
        for (var i = 0; i < verts.Length; i++) {
            var v = verts[i];
            DoSomething(v.x, v.y, v.z);
        }
    \end{minted}
    \caption{Common performance bottleneck in Unity \cite{unity:heap}. \ttt{mesh.vertices} should be cached.} \label{lst:unity:array:prop}
\end{listing}

The problem of boxing occurs when a value-type should be used by refrence, for instance when constructing a list of integers or appending a float to a string. This generates a small ammount of garbage, which can quickly accumulate, e.g. during list iterations. Furthermore, \cite{unity:optimisation} underlines the importance of avoiding \gls{LINQ}-statements all together, due to the garbage generated under the hood. \cite{unity:heap} recommends avoiding coding styles that requires passing functions as arguments and to completely avoid closures, due to the ammount of garbage generated by said language constructs.

\subsection{Garbage Collection Algorithm}
Unity uses the Boehm–Demers–Weiser \gls{GC}, which is a conservative mark-sweep \gls{GC}\cite{unity:heap}, originally created for automatic memory management in C and C++\cite{boehm2007transparent}. Mark-sweep algorithms are the simplest type of \glspl{GC} and has the primary disadvantages that they halt computation while running, increase in execution time as more objects are allocated and may fragment memory\cite{sestoft2017programming}.

The dotnet runtime uses a generational \gls{GC} with three generations for smaller objects and a single generation for large objects\cite{dotnet:gc}. The younger generations are collected more often than the higher and all surviving objects are moved to the older generations. Each time an older generation is collected, all younger generations are also collected. Generational \glspl{GC} have the advantage that short-lived object allocations has a smaller performance penalty, but the disadvantage that they introduce additional overhead if old objects contain references to young objects\cite{sestoft2017programming}. Depending on the system the dotnet runtime may use different \gls{GC} strategies, including concurrent versions\cite{dotnet:gc}. Concurrent \glspl{GC} can collect garbage concurenly with the computation, meaning that \gls{GC} pauses are minimised or entirely removed\cite{dotnet:gc}.

Mono has previously used the Boehm–Demers–Weiser \gls{GC}, but has since moved to a concurrent, generational \gls{GC} called sgen\cite{mono:gc}. We have previously mentioned that Unity uses the Mono runtime, which may cause some confusion, so a clarification is due. The Unity Engine supports two different runtimes: Mono and IL2CPP. The Mono runtime is a fork of the Mono runtime\cite{unity:mono:github}, meaning that updates to the official Mono is not necessarily applied to the Unity Engine's Mono runtime. The IL2CPP runtime \gls{AoT} compiles code in \gls{IL} to C++ and at the time of writing also uses the Boehm–Demers–Weiser \gls{GC}\cite{il2cpp:gc}. However, an \textit{\dquote{incremental garbage collector, which should reduce stutters and time spikes}} is listed on the roadmap for Unity's 2019.1.0 release\cite{unity:roadmap}.

\subsection{Functional Programming and Garbage Collection}
All these recommendations stand in direct contrast to the common practices employed in the pure functional programming paradigm. In functional programming it's typical to map over collections, which has two problems compared to this Unity performance guideline:
\begin{enumerate}
    \item map allocates a new collection instead of mutating the existing collection.
    \item map requires a function as one of the arguments, which defines what should happen to each of the elements in the collection.
\end{enumerate}
This practise also extends to other generalised constructs, such as the tree-walker employed in talents test case. These guidelines explain why Unity Technologies does not want to add F\# support despite over 3500 votes on their feedback forums in April 2018\cite{unity:fsharp}. The vote was later closed by Unity, without any explanation\footnote{In previous work \cite{p92018gameplay} he have cited the Unity forums to support this claim, but as of Feburary 2019 Unity has closed their feedback forums, meaning that this citation is no longer valid.}.

\subsection{Investigating Performance}
Unity's performance guidelines regarding \gls{GC} seems to convey the message that functional-style programming should be avoided in Unity. However, an investigation of Unity's integration with the runtime shows that a there is a considerable overhead in calling the pre-defined \ttt{MonoBehaviour}-methods (such as \ttt{Update})\cite{unity:runtime:calls}. In \cite{unity:runtime:calls} the author setups up two different scenes:
\begin{enumerate}
    \item A scene containing 10,000 separate \ttt{MonoBehaviours} with an \ttt{Update}-method that increments a variable.
    \item A scene containing one \ttt{MonoBehaviour}, which contains an array of 10,000 objects. Each time the \ttt{Update}-method is called, the \ttt{MonoBehaviour} iterates through the 10,000 objects and calls a custom \ttt{MyUpdate}-method.
\end{enumerate}
On an iPhone 6 the first approach took an average of 5.4ms to update the 10,000 objects, whereas the second took 0.22ms\cite{unity:runtime:calls}. In the first approach only 0.4\% of the time is spent actually executing the \ttt{Update}-code, the remaining 99.6\% is spent doing sanity checks, iterating \ttt{MonoBehaviours} and instrumenting calls from the native code into the runtime.

\subsubsection{Test Setup}
The question then arises if the (potentially) increased overhead from \gls{GC} can be outweighed by having a single \ttt{MonoBehaviour} manage several other behaviours in the same scene? In order to investigate, we reused the implementation of the Unit Management test case from the usability test (see \secref{usability:test:cases}). This solution is listed in \lstref{test:case:ai}. This test case may be solved by creating a collection of tuples: \ttt{(Unit, State)}. The state machine contains a series of unit management methods; one for each state. These methods take a unit as argument and returns a state. At each iteration the corresponding state's methods are mapped over the collection to create a new collection of game objects and their updated state, which is stored for subsequent updates. This approach avoids dealing with the problems of updating the list while iterating and potentially applying two updates to one \ttt{GameObject}. The advantage is that a single \ttt{MonoBehaviour} is in charge of updating all units in the \dquote{Realtime Strategy Game} and the disadvantage is that it generates substantially more garbage, as a new collection is allocated at each \ttt{Update}. We refer to this method as \dquote{Inverse} in the remainder of this section.

The other approach, here referred to as \dquote{Normal}, creates a \ttt{MonoBehaviour} for each unit, which contains it's own state machine. This has the advantage that we can exploit caching and generate less garbage, as suggested by Unity Technologies\cite{unity:optimisation}. It comes at the disadvantage that each unit must have its own \ttt{Update}-method, potentially introducing a large overhead\cite{unity:runtime:calls}.

\begin{listing}
    \begin{minted}{csharp}
        public void Update()
        {
            //Apply updates and store the updated states in a list
            var newStates = _stateList.Select(s =>
            {
                switch (s.state)
                {
                    case State.Fleeing:
                        return Flee(s.entity);
                    case State.Moving:
                        return Move(s.entity);
                    case State.Attacking:
                        return Attack(s.entity);
                    default: return (State.Moving, s.entity);
                }
            }).ToList();

            //zip the list with the old states to create tuples: (new state, old state)
            foreach (var statePair in newStates.Zip(_stateList, (sNew, sOld) => (sNew,sOld)))
            {
                //Compare old state and new state, initialise the unit for the new state if changed
                if (statePair.sNew.Item1 != statePair.sOld.state)
                {
                    _initialiseState(statePair.sNew.Item1, statePair.sNew.entity);
                    //Create a new list containing the updated unit
                    _stateLise = _stateList.Select(s => s.entity == shooter ? (state, shooter) ? s);
                }
            }
        }
    \end{minted}
    \caption{Possible solution for the Unit Management test cases.}
    \label{lst:test:case:ai}
\end{listing}

\subsubsection{Methodology}
We decided to implement the two approaches in both C\# and F\#. We run the test using the il2cpp runtime under Unity 2019.1.0f2. In all test cases we used a \ttt{MonoBehaviour} written in C\# to measure the time between each \ttt{Update}-call, i.e. the time it takes to generate a frame. We decided to run the test in five setups with 500, 1000, 1500, 2000 and 2500 units. For each setup we generated 900 frames, as that corresponds to 15 seconds of gameplay at 60 \gls{FPS}. Each measurement was added to a \ttt{HashSet}, which was written to a CSV file after the test. This means that the measurements include all game-related code, both including rendering, physics and so alike. However, as this system is ultimately going to be used to develop games, we feel that delta time (or equivalently \gls{FPS}) is a good metric, as that is of utmost importance to the player.

The following research questions outlines the intend of the experiment:
\begin{itemize}
    \item How does the performance penalty from extensive garbage generation compare to the performance penalty from an incresed number of calls between unmanaged and managed runtimes?
    \item Does \gls{AoT}-compilation in the il2cpp runtime actually provide a speed up?
    \item Does the use of F\# (and \gls{FRP}) introduce an additional overhead.
\end{itemize}

\section{Results}
The average \gls{FPS} over the 900 frames are listed in \tableref{unity:ai} and \tableref{unity:ai:runtime}. The results indicate first and foremost that the Normal approach (i.e. separate \ttt{MonoBehaviour}s with their own statemachine and \ttt{Update}-method) in C\# and F\# are comparable in these problem sizes. The results also suggest that the inverse state-machine approach is comparable to normal C\#. These results may be interpreted as meaning that extensive garbage generation has the same penalty as Unity's call from native code into managed code. We also observe that the inverse FRP state machine performs notably worse than the other approaches. We will go into greater depth as to why in the following section. Finally the resuls also show that il2cpp provides a speed up that results in roughly 2-4 more \gls{FPS} in C\# Normal, Inverse and F\# Normal.

Another interesting observation we made during the test is that there is a very large spike in the time it takes to generate the third frame. This spike is around 20 times the time it takes to generate the other scenes. One could explain this spike in Mono as runtime-optimisation, but as it is also present in il2cpp, which is \gls{AoT}, that cannot be the case. We do therefore not know what causes the spike.

\makeTable{
    { c | c | c | c | c | c }
    \textbf{Strategy} & \textbf{50 Units} & \textbf{100 Units} & \textbf{150 Units} & \textbf{200 Units} & \textbf{250 Units} \\\hline
    C\# Normal & 56.1 & 56.5 & 56.3 & 56.7 & 56.3 \\\hline
    C\# Inverse & 56.4 & 56.5 & 55.9 & 56.7 & 55.7 \\\hline
    F\# & 56.5 & 56.1 & 53.4 & 56.1 & 56.1 \\\hline
    FRP Inverse & 28.6 & 16.1 & 10.0 & 7.7 & 6.2 \\
    }{Average framerate when simulating the given number of units in Unity's Mono runtime.}{unity:ai}
\makeTable{
    { c | c | c }
    \textbf{Strategy} & \textbf{Mono} & \textbf{il2cpp} \\\hline
    C\# Normal & 56.3 & 59.4 \\\hline
    C\# Inverse & 55.7 & 59.4 \\\hline
    F\# Normal & 56.1 & 57.9\\\hline
    FRP Inverse & 6.2 & 5.9 \\
}{Average framerate in Unity's two runtimes measured with 250 unites in the scene.}{unity:ai:runtime}


\subsection{Performance Penalty from Extensive Garbage Generation}
The results are listed in \tableref{unity:ai} and plotted in \figref{ai:benchmark}. The results indicate that the Normal approach (i.e. separate \ttt{MonoBehaviour}s with their own state machine and \ttt{Update}-method) in C\# and F\# are comparable in these problem sizes. The results also suggest that the inverse state-machine approach is comparable to normal C\#. These results may be interpreted as meaning that extensive garbage generation has the same penalty as Unity's call from native code into managed code. We also observe that the inverse FRP state machine performs notably worse than the other approaches as the number of units grow. We will go into greater depth as to why in the following section.

\begin{table}[H]
    \sisetup{round-mode=places}
    \rowcolors{1}{}{lightgray}
    \makebox[\textwidth][c]{
    \begin{tabular}{P{4cm} | S[round-precision=2] | S[round-precision=2] | S[round-precision=2] | S[round-precision=2]}
        \textbf{Number of Units} & \textbf{C\#} & \textbf{C\# Inverse} & \textbf{F\#} & \textbf{FRP Inverse}
        \csvreader[head to column names]{00-data/ai-benchmark.csv}
        {1=\strategy, 2=\csharp, 3=\cinverse, 4=\fsharp, 5=\frp} % <Column number>=<Macro>
        {\\\hline \strategy & \csharp & \cinverse & \fsharp & \frp}
    \end{tabular}}
    \caption{Average framerate when simulating the given number of units in Unity's Mono runtime.}
    \label{tab:unity:ai}
\end{table}

\barChart*[12][\symbolic{Strategy,500,1000,1500,2000,2500}][Average FPS][Number of Units]{Average FPS in Unit Management benchmark}{ai:benchmark}{
    \plotData{Csharp Normal}{\aiBenchmarkData}
    \plotData{Csharp Inverse}{\aiBenchmarkData}
    \plotData{Fsharp Normal}{\aiBenchmarkData}
    \plotData{FRP Inverse}{\aiBenchmarkData}
}

\subsection{Performance of Runtimes}
The results, listed in \tableref{unity:ai:runtime} and plotted in \figref{ai:benchmark:runtime}, show that il2cpp does not necessarily provide a speed up, as C\# Normal is faster in Mono and il2cpp provides roughly 2 more \gls{FPS} in C\# Inverse and F\# Normal.

Another interesting observation we made during the test is that there is a very large spike in the time it takes to generate the third frame. This spike is around 20 times the time it takes to generate the other frames. One could explain this spike in Mono as runtime-optimisation, but as it is also present in il2cpp, which is \gls{AoT}, that cannot be the case. We do therefore not know what causes the spike.

\begin{table}[H]
    \sisetup{round-mode=places}
    \rowcolors{1}{}{lightgray}
    \makebox[\textwidth][c]{
    \begin{tabular}{P{4cm} | S[round-precision=2] | S[round-precision=2]}
        \textbf{Runtime} & \textbf{il2cpp} & \textbf{Mono}
        \csvreader[head to column names]{00-data/ai-benchmark-runtimes.csv}
        {1=\strategy, 2=\iltocpp, 3=\mono} % <Column number>=<Macro>
        {\\\hline \strategy & \iltocpp & \mono}
    \end{tabular}}
    \caption{Average framerate in Unity's two runtimes measured with 250 unites in the scene.}
    \label{tab:unity:ai:runtime}
\end{table}

\barChart*[12][\symbolic{Strategy,Csharp Normal,Csharp Inverse,Fsharp Normal,FRP Inverse}][Average FPS][Strategy]{Average FPS in Unit Management benchmark}{ai:benchmark:runtime}{
    \plotData{Mono}{\aiBenchmarkRuntimesData}
    \plotData{il2cpp}{\aiBenchmarkRuntimesData}
}

\subsection{Performance of the FRP-system}

The results are plotted in \figref{ai:benchmark:overhead}. The results show that \gls{FRP} introduces additional overhead. This overhead results in a decrease of ten \gls{FPS} on average over the 900 frames. On the other hand, the \gls{FRP}-system yields a smoother curve, which means that the game will be subject to less stuttering and fewer lag spikes.

\lineChart[xtick={100, 200, 300, 400, 500, 600, 700, 800}][FPS][Frame No.]{FPS for each frame in FRP and C\# Inverse}{ai:benchmark:overhead}{
    \plotData{Csharp}{\aiBenchmarkOverheadData}
    \plotData{FRP}{\aiBenchmarkOverheadData}
}

The problems with the \gls{FRP}-system is that each \ttt{FRPBehaviour} is actually a full-blown \gls{FRP}-system, which could very well be refactored into a singleton.

Solving this problem would require a larger refactoring, as this relates to the Unity lifecycle of \ttt{GameObject}s. First and foremost some Unity methods are required to be tied to the \ttt{GameObject} they belong to. Examples of such methods are \ttt{OnCollisionEnter} and \ttt{OnTriggerExit}. Other methods, such as \ttt{Update} and reacting to keyboard strokes could, on the other hand, be tied to a \ttt{FRPEngine}. The problem here arises when \ttt{GameObject}s are destroyed. We have not added support to remove \ttt{FRPBehaviour}s from the \gls{FRP}-system, as the current version \dquote{cleans} up after itself when \ttt{GameObject}s are destroyed. This is to be understood in the sense that the whole system is deallocated and thus never risks invoking event handlers on objects that have been destroyed.

In order to truely determine whether or not \gls{FRP} comes with a performance penalty, these changes would have to be incorporated.

\section{Unity's Incremental Garbage Collector}
