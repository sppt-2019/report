\subsection{Threats to Validity} \label{sec:validity}
In this section we will examine potential sources or errors and other threats to validity. Such threats are categorised as either an internal threat or an external threat. An internal threat occurs when data is mishandled, misinterpreted or in some other way skewed to such a degree that the results are untrustworthy. The second category consists of errors caused by the data being inapplicable to other cases. This inline with terminology outlined in \cite{mcleod:validity}.


\subsubsection{Internal Validity}
In this section the internal validity is explored. The goal of this section is map out the possible  shortcomings originating from data handling and interpretation. Each potential threat is explained in turn and actions undertaken to mediate the threat are outlined. In some cases a threat cannot be sufficiently mediated, in which case it is simply listed.

\paragraph{Evaluation Parameters}
The user tests where evaluated in accordance with the champagne prototyping method (see \secref{champagne}). This methodology is intended to be used to measure the usability of a single feature, not an entire programming language. Therefore it was modified to fit our case better. The methodology consists of two other usability techniques: cognitive dimensions and attention investment models (see \secref{cog-dim} and \secref{attention-investment}). We modified the cognitive dimensions aspect to focus on the languages as a whole and kept the feature focus of attention investment. Thus the evaluation parameters where centered on the users experience with \fs and their understanding of the \gls{FRP} system.

The cognitive dimensions framework is originally intended to  estimate the usability, or provide vocabulary to such an estimation, of a notational system such as a programming language. Therefore our modification of champagne prototyping is to use cognitive dimensions for its original purpose. Furthermore, a single aspect of discount method for language evaluation was used, namely the sample sheet (see \secref{discount-method}). This was employed to assist test participants with \fs.

\paragraph{Task Difficulty}
The user test consisted of a number tasks that participants where asked to complete. These tasks where inspired by game development scenarios and applicability of functional idioms. Before the test we where worried that some tests where more difficult than others. This could skew the results somewhat since, participants completing the more difficult tasks would struggle more then participants completing the easier tasks. The dialogue tree task (see \secref{usability:test:cases}) presented a much more difficult problem than expected. The task relied on recursion and tree structures which where unfamiliar to participants.

After the user test is became apparent that some tasks where indeed more difficult than others, significantly so in some cases. The difficulty of the tasks themselves did not affect the results to the degree we had expected, instead the difficult tasks brought conflicting idioms and faulty problem solving approaches to light that may not have been as apparent in the easier tasks.

\paragraph{Task Presentation}
During the tests it became apparent that some tasks where not formulated clearly enough. This meant that participants misunderstood the task and therefore did not sufficiently complete the task. These misunderstandings came from unclear task descriptions and lacking context. To mediate this we conducted a pilot test with another software student. Using this test, clarified several tasks before the user test. Unfortunately this test did not catch all the obscurities in the tasks.

Furthermore, some tasks could have been constructed better. An example of this is the dialogue tree task, instead of constructing a class that participants would use, an interface could have been formulated. This would have implicitly clarified the purpose of the class.

\paragraph{Sample Size}
A test setup with six participants and eight test cases does provide limitations.

\subsubsection{External Validity}
\metasheep

\paragraph{Applicability to Game Development}

\paragraph{Previous Experience}

%Generalisability
